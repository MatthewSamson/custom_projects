{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23028, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading up the data\n",
    "data = pd.read_csv('data.csv')\n",
    "# shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['location_name', 'count', 'max temp', 'mean temp', 'min temp',\n",
       "       'snow on grnd (cm)', 'total precip (mm)', 'total rain (mm)',\n",
       "       'total snow (cm)', 'date'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features in the data\n",
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Pre-process a dataframe\n",
    "    \n",
    "    :param pd.DataFrame df: raw dataframe from data.csv\n",
    "    \n",
    "    :returns pd.DataFrame processed_df: processed dataframe\n",
    "    ''' \n",
    "    group_date_location = df.groupby(['date', 'location_name']).sum()\n",
    "    group_date = group_date_location.groupby(['date']).sum()\n",
    "    print(\"Shape after group by and summation: \", group_date.shape)\n",
    "    \n",
    "    group_date['total count'] = \"\"\n",
    "    \n",
    "    for i, ct in enumerate(group_date['count']):\n",
    "        if ct < 2000:\n",
    "            group_date['total count'][i] = \"less than 2000\"\n",
    "        if ct > 2000 and ct < 10000:\n",
    "            group_date['total count'][i] = \"2000 to 10000\"\n",
    "        if ct > 10000:\n",
    "            group_date['total count'][i] = \"over 10000\"\n",
    "    \n",
    "    print(\"New features of total count set!\")\n",
    "    print(\"Saving file as processed_data.csv...\")\n",
    "    group_date.to_csv('processed_data.csv')\n",
    "    \n",
    "    return group_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after group by and summation:  (3282, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\sunny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\sunny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features of total count set!\n",
      "Saving file as processed_data.csv...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>max temp</th>\n",
       "      <th>mean temp</th>\n",
       "      <th>min temp</th>\n",
       "      <th>snow on grnd (cm)</th>\n",
       "      <th>total precip (mm)</th>\n",
       "      <th>total rain (mm)</th>\n",
       "      <th>total snow (cm)</th>\n",
       "      <th>total count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>-17.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>less than 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>-23.8</td>\n",
       "      <td>-26.6</td>\n",
       "      <td>-29.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>less than 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>-23.4</td>\n",
       "      <td>-34.2</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>less than 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>-22.5</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-31.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>less than 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-15.6</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>less than 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count  max temp  mean temp  min temp  snow on grnd (cm)  \\\n",
       "date                                                                  \n",
       "2010-01-01      0      -7.5      -12.3     -17.1               54.0   \n",
       "2010-01-02      0     -23.8      -26.6     -29.2               42.0   \n",
       "2010-01-03      0     -23.4      -34.2     -45.0               63.0   \n",
       "2010-01-04      0     -22.5      -27.0     -31.5               63.0   \n",
       "2010-01-05      0     -10.0      -15.6     -21.2               42.0   \n",
       "\n",
       "            total precip (mm)  total rain (mm)  total snow (cm)  \\\n",
       "date                                                              \n",
       "2010-01-01               15.0              0.0             22.8   \n",
       "2010-01-02                3.8              0.0              5.2   \n",
       "2010-01-03                6.0              0.0              9.0   \n",
       "2010-01-04                3.0              0.0              6.0   \n",
       "2010-01-05                2.0              0.0              3.0   \n",
       "\n",
       "               total count  \n",
       "date                        \n",
       "2010-01-01  less than 2000  \n",
       "2010-01-02  less than 2000  \n",
       "2010-01-03  less than 2000  \n",
       "2010-01-04  less than 2000  \n",
       "2010-01-05  less than 2000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = preprocessing(data)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class(df):\n",
    "    dframe = df.copy()\n",
    "    \n",
    "    dframe['class'] = None\n",
    "                \n",
    "    for i, cla in enumerate(dframe['total count']):\n",
    "        if cla == \"less than 2000\":\n",
    "            dframe['class'][i] = 0\n",
    "            \n",
    "        if cla == \"2000 to 10000\":\n",
    "            dframe['class'][i] = 1\n",
    "            \n",
    "        if cla == \"over 10000\":\n",
    "            dframe['class'][i] = 2\n",
    "            \n",
    "    dframe = dframe.drop(columns = ['total count', 'count'])\n",
    "    return dframe\n",
    "\n",
    "\n",
    "def scale_values(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data.values)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_engineering(processed_df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    '''\n",
    "    Perform data engineering on processed dataframe\n",
    "\n",
    "    :param pd.DataFrame processed_df: output of preprocess()\n",
    "\n",
    "    :returns pd.DataFrame train_df: training set of the engineered dataframe\n",
    "    :returns pd.DataFrame test_df: test set of the engineered dataframe\n",
    "    '''\n",
    "    train, test = train_test_split(processed_df, test_size = 0.2, random_state = 123)\n",
    "    print(\"Saving train data to train.csv\")\n",
    "    print(\"Saving test data to test.csv\")\n",
    "    train.to_csv(\"train.csv\")\n",
    "    test.to_csv(\"test.csv\")\n",
    "    \n",
    "    # convert labels to class values\n",
    "    train_class = convert_class(train)\n",
    "    test_class = convert_class(test)\n",
    "    print(\"Labeling complete!\")\n",
    "\n",
    "    # scale the datasets - normalization\n",
    "    train_scale = scale_values(train_class.iloc[:, :-1])\n",
    "    test_scale = scale_values(test_class.iloc[:, :-1])\n",
    "    print(\"Scaling complete!\")\n",
    "    \n",
    "    train_df = (train_scale, train_class['class'].values)\n",
    "    test_df = (test_scale, test_class['class'].values)\n",
    "    \n",
    "    return (train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train data to train.csv\n",
      "Saving test data to test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\sunny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\sunny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling complete!\n",
      "Scaling complete!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data_engineering(processed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Classical machine learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_ml(train_df: pd.DataFrame, test_df: pd.DataFrame) -> ('classifier', 'accuracy', 'confusion matrix'):\n",
    "    '''\n",
    "    Use classical machine learning methods to predict total counts\n",
    "\n",
    "    :param pd.DataFrame train_df: training set dataframe\n",
    "    :param pd.DataFrame test_df: test set dataframe\n",
    "\n",
    "    :returns 'classifier': trained classifier\n",
    "    :returns 'accuracy': tuple of training accuracy and testing accuracy\n",
    "    :returns 'confusion matrix': confusion matrix on test set\n",
    "    '''\n",
    "    \n",
    "    x_train, y_train = train_df[0], train_df[1].astype('int')\n",
    "    x_test, y_test = test_df[0], test_df[1].astype('int')\n",
    "    \n",
    "    # creating a classifier, using the support vector classifier\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    # test accuracy\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of the trained model is: {}%\".format(round(acc, 5)*100))\n",
    "    \n",
    "    # building the confusion matrix\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Final confusion matrix is: \")\n",
    "    print(conf)\n",
    "    \n",
    "    return clf, acc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Accuracy of the trained model is: 76.408%\n",
      "Final confusion matrix is: \n",
      "[[249   8   1]\n",
      " [ 73 130  31]\n",
      " [  1  41 123]]\n"
     ]
    }
   ],
   "source": [
    "classifier, accuracy, confusion_mat = classical_ml(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, valid_loss, test_loss = [], [], []\n",
    "\n",
    "def nn_ml(train_df: pd.DataFrame, test: pd.DataFrame) ->  ('model', 'test_accuracy'):\n",
    "    '''\n",
    "    Use neural networks to predict total counts\n",
    "\n",
    "    :param pd.DataFrame train_df: training set dataframe\n",
    "    :param pd.DataFrame test_df: test set dataframe\n",
    "\n",
    "    :returns 'model': trained model\n",
    "    :returns 'test_accuracy': accuracy on test set\n",
    "    '''\n",
    "    \n",
    "    onehot_enc = OneHotEncoder()\n",
    "    train_df_onehot = onehot_enc.fit_transform(train_df[1].astype('int').reshape(-1, 1)).toarray()\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(train_df[0], train_df_onehot, test_size=0.35)\n",
    "    x_tra = torch.tensor(x_train, dtype=torch.float)\n",
    "    y_tra = torch.tensor(y_train, dtype=torch.float)\n",
    "\n",
    "    x_val = torch.tensor(x_valid, dtype=torch.float)\n",
    "    y_val = torch.tensor(y_valid, dtype=torch.float)\n",
    "    \n",
    "    # use the nn package to define our model and loss function.\n",
    "    model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(x_tra.shape[1], 25),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(25, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, y_tra.shape[1]),\n",
    "    torch.nn.Sigmoid(),)\n",
    "    \n",
    "    print(\"Model Architecture: \")\n",
    "    print(model)\n",
    "    \n",
    "    epochs = 100\n",
    "    stop_counter = 0\n",
    "    early_stop = 5\n",
    "    learning_rate = 1e-4\n",
    "    every = 10\n",
    "    threshold = 15.0\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    onehot_enc = OneHotEncoder()\n",
    "    train_df_onehot = onehot_enc.fit_transform(train_df[1].astype('int').reshape(-1, 1)).toarray()\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(train_df[0], train_df_onehot, test_size=0.2)\n",
    "    x_tra = torch.tensor(x_train, dtype=torch.float)\n",
    "    y_tra = torch.tensor(y_train, dtype=torch.float)\n",
    "\n",
    "    x_val = torch.tensor(x_valid, dtype=torch.float)\n",
    "    y_val = torch.tensor(y_valid, dtype=torch.float)\n",
    "\n",
    "    train_sum_loss, valid_sum_loss, test_sum_loss = 0, 0, 0\n",
    "\n",
    "    for t in range(1, epochs + 1):\n",
    "        train_score, valid_score = 0, 0\n",
    "        train_sum_loss, valid_sum_loss = 0, 0\n",
    "\n",
    "        #####set the model to train mode based on the train data\n",
    "        model.train()\n",
    "        for i, vec in enumerate(x_tra):\n",
    "            # forward pass\n",
    "            y_train_pred = model(vec)\n",
    "            # compute and print loss\n",
    "            loss = loss_fn(y_train_pred, y_tra[i])\n",
    "            # collect the loss\n",
    "            train_sum_loss += loss.item()\n",
    "            # zero the gradient before back prop\n",
    "            optimizer.zero_grad()\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # optimizer makes an update to its parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "        #####set the model to evaluate mode based on the validation data\n",
    "        model.eval()\n",
    "        for i, vec in enumerate(x_val):\n",
    "            # forward pass\n",
    "            y_valid_pred = model(vec)\n",
    "            # compute and print loss\n",
    "            loss = loss_fn(y_valid_pred, y_val[i])\n",
    "            valid_sum_loss += loss.item()\n",
    "\n",
    "        train_loss.append(train_sum_loss / x_tra.shape[0])\n",
    "        valid_loss.append(valid_sum_loss / x_val.shape[0])\n",
    "        \n",
    "        train_score = round((train_sum_loss / x_tra.shape[0]) * 100, 3)\n",
    "        valid_score = round((valid_sum_loss / x_val.shape[0]) * 100, 3)\n",
    "\n",
    "        #if t % every == 0:\n",
    "        print(\"Epoch \", t, (t / epochs) * 100, \"% complete...\")\n",
    "        print(\"Train loss: \", train_score, \"Validation score: \", valid_score)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if valid_score < threshold:\n",
    "            stop_counter += 1\n",
    "\n",
    "            if stop_counter == early_stop:\n",
    "                print(\"Threshold reached after \", t, \" iterations!\")\n",
    "                print(\"Training Complete after Early Stop!\")\n",
    "                break\n",
    "                \n",
    "    \n",
    "    #####testing the model after training and validataion\n",
    "    test_df_onehot = onehot_enc.fit_transform(test[1].astype('int').reshape(-1, 1)).toarray()\n",
    "    \n",
    "    x_test = torch.tensor(test[0], dtype=torch.float)\n",
    "    y_test = torch.tensor(test_df_onehot, dtype=torch.float)\n",
    "    \n",
    "    model.eval()\n",
    "    for i, vec in enumerate(x_test):\n",
    "        # forward pass with test dataset\n",
    "        y_test_pred = model(vec)\n",
    "        # compute and print loss\n",
    "        loss = loss_fn(y_test_pred, y_test[i])\n",
    "        test_loss.append(loss.item())\n",
    "        test_sum_loss += loss.item()\n",
    "    \n",
    "    test_avg_loss = (test_sum_loss / y_test.shape[0]) * 100\n",
    "    test_acc = 100 - test_avg_loss\n",
    "    #print(\"Total test loss: \", test_sum_loss)\n",
    "    print(\"Total average test loss: \", round(test_avg_loss, 4), \"%\")\n",
    "    print(\"Total average test accuracy: \", round(test_acc, 4), \"%\")\n",
    "\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture: \n",
      "Sequential(\n",
      "  (0): Linear(in_features=7, out_features=25, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=25, out_features=10, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 0.01 % complete...\n",
      "Train loss:  24.013 Validation score:  22.478\n",
      "\n",
      "\n",
      "Epoch  2 0.02 % complete...\n",
      "Train loss:  21.914 Validation score:  21.737\n",
      "\n",
      "\n",
      "Epoch  3 0.03 % complete...\n",
      "Train loss:  21.531 Validation score:  21.4\n",
      "\n",
      "\n",
      "Epoch  4 0.04 % complete...\n",
      "Train loss:  21.133 Validation score:  20.869\n",
      "\n",
      "\n",
      "Epoch  5 0.05 % complete...\n",
      "Train loss:  20.535 Validation score:  20.117\n",
      "\n",
      "\n",
      "Epoch  6 0.06 % complete...\n",
      "Train loss:  19.736 Validation score:  19.175\n",
      "\n",
      "\n",
      "Epoch  7 0.06999999999999999 % complete...\n",
      "Train loss:  18.783 Validation score:  18.128\n",
      "\n",
      "\n",
      "Epoch  8 0.08 % complete...\n",
      "Train loss:  17.773 Validation score:  17.104\n",
      "\n",
      "\n",
      "Epoch  9 0.09 % complete...\n",
      "Train loss:  16.832 Validation score:  16.227\n",
      "\n",
      "\n",
      "Epoch  10 0.1 % complete...\n",
      "Train loss:  16.048 Validation score:  15.535\n",
      "\n",
      "\n",
      "Epoch  11 0.11 % complete...\n",
      "Train loss:  15.431 Validation score:  15.01\n",
      "\n",
      "\n",
      "Epoch  12 0.12 % complete...\n",
      "Train loss:  14.96 Validation score:  14.616\n",
      "\n",
      "\n",
      "Epoch  13 0.13 % complete...\n",
      "Train loss:  14.602 Validation score:  14.32\n",
      "\n",
      "\n",
      "Epoch  14 0.13999999999999999 % complete...\n",
      "Train loss:  14.329 Validation score:  14.095\n",
      "\n",
      "\n",
      "Epoch  15 0.15 % complete...\n",
      "Train loss:  14.117 Validation score:  13.923\n",
      "\n",
      "\n",
      "Epoch  16 0.16 % complete...\n",
      "Train loss:  13.95 Validation score:  13.785\n",
      "\n",
      "\n",
      "Threshold reached after  16  iterations!\n",
      "Training Complete after Early Stop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total average test loss:  13.2321 %\n",
      "Total average test accuracy:  86.7679 %\n"
     ]
    }
   ],
   "source": [
    "nn, acc = nn_ml(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.plot(np.arange(len(train_loss)), train_loss, 'r-')\n",
    "plt.plot(np.arange(len(valid_loss)), valid_loss, 'b-')\n",
    "#plt.plot(np.arange(len(test_loss)), test_loss, 'g-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1065, 0.4168, 0.4416], grad_fn=<SigmoidBackward>),\n",
       " tensor([0., 0., 1.]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.eval()\n",
    "x_test = torch.tensor(test_df[0], dtype=torch.float)\n",
    "onehot_enc = OneHotEncoder()\n",
    "test_df_onehot = onehot_enc.fit_transform(test_df[1].astype('int').reshape(-1, 1)).toarray()\n",
    "y_test = torch.tensor(test_df_onehot, dtype=torch.float)\n",
    "am = nn(x_test[0])\n",
    "am, y_test[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
